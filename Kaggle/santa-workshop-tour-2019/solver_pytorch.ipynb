{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: constraints; cost function? why nega score?; goal is to achieve comparable performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/96/c97c8a0ea8f66de41f452925b521bcfdebef6fffb899dc704fc269d87563/torch-1.3.1-cp36-none-macosx_10_7_x86_64.whl (71.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 71.1MB 657kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/songxu/Code/venv/lib/python3.6/site-packages (from torch) (1.16.4)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.3.1\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/pavelvod/pytorch-starter-solution\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giftCostsNp (5000, 100): [i,j] means the gift cost when i-th family choses j-th day.\n",
    "row, col = 5000, 100\n",
    "giftCostsNp = np.zeros((row, col))\n",
    "familySizesNp = np.zeros((row, 1))\n",
    "\n",
    "familyDataNp = utils.readDataDf().values\n",
    "\n",
    "for i in range(row):\n",
    "    familySizesNp[i] = familyDataNp[i, -1]\n",
    "    for j in range(col):\n",
    "        giftCostsNp[i,j] = utils.getCurGift(assignDay=j, \n",
    "                                          familyPreferencesList=familyDataNp[i, 1:-1].tolist(), \n",
    "                                          familySize=familySizesNp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, giftCostsNp, familySizesNp):\n",
    "        super().__init__()\n",
    "        self.giftCostsTc = torch.from_numpy(giftCostsNp).type(torch.float32)\n",
    "        self.familySizesTc = torch.from_numpy(familySizesNp).type(torch.float32)\n",
    "        self.assignWeightsTc = torch.nn.Parameter(data=torch.Tensor(5000, 100), requires_grad=True)\n",
    "        self.assignWeightsTc.data.uniform_(0,5) # weight initialization?\n",
    "        \n",
    "    def forward(self):\n",
    "        assignProbTc = F.softmax(self.assignWeightsTc, dim=1)\n",
    "#         print(self.giftCostsTc.shape, assignProbTc.shape)\n",
    "        giftCostTotalTc = (self.giftCostsTc * assignProbTc).sum()\n",
    "        \n",
    "        NdTc = (assignProbTc.transpose(0,1) @ self.familySizesTc).sum(axis=1)\n",
    "#         print(F.softmax(NdTc).max(), F.softmax(NdTc).argmax())\n",
    "        NdTcCat = torch.zeros(101, dtype=torch.float32)\n",
    "        NdTcCat[:-1] = NdTc\n",
    "        NdTcCat[-1] = NdTc[-1]\n",
    "        \n",
    "#         print(\"exponent: \", 0.5+abs(NdTcCat[:-1]-NdTcCat[1:])/50.)\n",
    "        cleanCostTotalTc = ((NdTc-125.)/400. * NdTc**(0.5+abs(NdTcCat[:-1]-NdTcCat[1:])/50.)).sum()\n",
    "        \n",
    "        penaltyCostTotalTc = (torch.relu(125.-NdTc)**2 + torch.relu(NdTc-300.)**2).sum() * 1000000\n",
    "        return giftCostTotalTc, cleanCostTotalTc, penaltyCostTotalTc, NdTc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/songxu/PycharmProjects/Data_Science/Kaggle/santa-workshop-tour-2019/utils.py'>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def cost_function():\n",
    "#     return None\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(giftCostsNp, familySizesNp)\n",
    "best_score = 10e10\n",
    "best_pos = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max's: tensor([0.5745, 0.9499, 0.9359,  ..., 0.9948, 0.3971, 0.4943])\n",
      "NdList[:10] inside getTotalPenalty(): [67, 30, 184, 154, 233, 243, 243, 233, 265, 273]\n",
      "NdTc[:10]: tensor([125.4360, 135.2435, 187.0518, 178.2332, 218.5107, 246.3865, 234.9274,\n",
      "        252.8669, 259.5987, 273.9169])\n",
      "\n",
      "max's: tensor([0.6099, 0.9748, 0.8685,  ..., 0.9974, 0.4094, 0.5429])\n",
      "NdList[:10] inside getTotalPenalty(): [67, 38, 176, 179, 240, 261, 249, 231, 269, 283]\n",
      "NdTc[:10]: tensor([125.2969, 157.3845, 189.3737, 197.6497, 230.2791, 251.0608, 232.4649,\n",
      "        249.0865, 255.8413, 275.3265])\n",
      "\n",
      "max's: tensor([0.6419, 0.9868, 0.7703,  ..., 0.9986, 0.4250, 0.7851])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 97, 197, 216, 291, 268, 240, 225, 248, 271]\n",
      "NdTc[:10]: tensor([125.0205, 217.6847, 205.8865, 235.1218, 260.0786, 256.9468, 233.2404,\n",
      "        240.7294, 251.0780, 272.1079])\n",
      "\n",
      "max's: tensor([0.6619, 0.9924, 0.8450,  ..., 0.9991, 0.4365, 0.9069])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 127, 241, 263, 287, 274, 233, 223, 243, 269]\n",
      "NdTc[:10]: tensor([125.1573, 225.0706, 234.1841, 264.9507, 281.7942, 262.9737, 237.2393,\n",
      "        236.3465, 248.2562, 270.0950])\n",
      "\n",
      "max's: tensor([0.6803, 0.9952, 0.8454,  ..., 0.9993, 0.4454, 0.9230])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 154, 264, 283, 295, 277, 233, 217, 238, 266]\n",
      "NdTc[:10]: tensor([125.7365, 230.9024, 253.8653, 283.4799, 291.0675, 269.6912, 243.1575,\n",
      "        237.1681, 247.6390, 267.5855])\n",
      "\n",
      "max's: tensor([0.6980, 0.9968, 0.8465,  ..., 0.9995, 0.4534, 0.9409])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 179, 275, 304, 299, 276, 240, 223, 243, 266]\n",
      "NdTc[:10]: tensor([125.0072, 239.1322, 265.3979, 293.4929, 295.8849, 274.3736, 247.8922,\n",
      "        238.0564, 247.3405, 266.2428])\n",
      "\n",
      "max's: tensor([0.7154, 0.9978, 0.8502,  ..., 0.9996, 0.4590, 0.9560])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 192, 272, 316, 302, 267, 240, 225, 243, 261]\n",
      "NdTc[:10]: tensor([125.0465, 242.9730, 270.7456, 298.5019, 299.6143, 278.3392, 251.5512,\n",
      "        239.0359, 246.7304, 265.6281])\n",
      "\n",
      "max's: tensor([0.7281, 0.9984, 0.8590,  ..., 0.9997, 0.4631, 0.9698])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 201, 272, 313, 286, 271, 245, 227, 240, 257]\n",
      "NdTc[:10]: tensor([124.9944, 249.1697, 271.7019, 298.1982, 298.2159, 280.4228, 254.8006,\n",
      "        241.3511, 246.9906, 265.4153])\n",
      "\n",
      "max's: tensor([0.7418, 0.9987, 0.8722,  ..., 0.9998, 0.4669, 0.9798])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 245, 277, 300, 286, 274, 261, 235, 240, 257]\n",
      "NdTc[:10]: tensor([124.6814, 300.0094, 280.6893, 299.7192, 299.3212, 281.5510, 256.1452,\n",
      "        242.4336, 246.2251, 264.4738])\n",
      "\n",
      "max's: tensor([0.7556, 0.9990, 0.8917,  ..., 0.9998, 0.4705, 0.9867])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 245, 294, 298, 286, 272, 261, 235, 244, 254]\n",
      "NdTc[:10]: tensor([124.6810, 300.0095, 285.7974, 298.9565, 299.9775, 282.6486, 257.5110,\n",
      "        243.2756, 245.2975, 264.8102])\n",
      "\n",
      "max's: tensor([0.7662, 0.9992, 0.9027,  ..., 0.9998, 0.4740, 0.9909])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 249, 296, 298, 292, 275, 261, 235, 247, 254]\n",
      "NdTc[:10]: tensor([124.6737, 299.9741, 287.5614, 298.0524, 299.1829, 282.9617, 258.1513,\n",
      "        242.9047, 244.5976, 264.6459])\n",
      "\n",
      "max's: tensor([0.7769, 0.9994, 0.9159,  ..., 0.9998, 0.4768, 0.9938])\n",
      "NdList[:10] inside getTotalPenalty(): [80, 249, 302, 298, 295, 275, 263, 235, 242, 252]\n",
      "NdTc[:10]: tensor([124.6771, 300.0530, 287.9861, 299.7129, 299.5799, 283.1893, 258.4786,\n",
      "        243.1467, 243.9557, 264.2542])\n",
      "\n",
      "max's: tensor([0.7845, 0.9995, 0.9290,  ..., 0.9999, 0.4794, 0.9959])\n",
      "NdList[:10] inside getTotalPenalty(): [80, 249, 308, 300, 300, 288, 263, 235, 237, 248]\n",
      "NdTc[:10]: tensor([124.6822, 300.0103, 288.1734, 299.5136, 299.8090, 283.4366, 258.7896,\n",
      "        243.6862, 243.6954, 263.9486])\n",
      "\n",
      "max's: tensor([0.7940, 0.9995, 0.9364,  ..., 0.9999, 0.4813, 0.9972])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 249, 304, 300, 305, 295, 263, 230, 241, 251]\n",
      "NdTc[:10]: tensor([124.6829, 300.0101, 288.1409, 299.4035, 299.2432, 283.0511, 258.4429,\n",
      "        243.7371, 243.7640, 263.9952])\n",
      "\n",
      "max's: tensor([0.8006, 0.9996, 0.9429,  ..., 0.9999, 0.4830, 0.9981])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 249, 298, 296, 305, 294, 267, 226, 238, 251]\n",
      "NdTc[:10]: tensor([124.6918, 300.0187, 288.4998, 299.8761, 299.8663, 282.8647, 257.9441,\n",
      "        243.9722, 244.1508, 264.1312])\n",
      "\n",
      "max's: tensor([0.8073, 0.9997, 0.9486,  ..., 0.9999, 0.4841, 0.9987])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 249, 296, 299, 305, 294, 267, 232, 244, 255]\n",
      "NdTc[:10]: tensor([124.6818, 300.0013, 288.1953, 299.3588, 299.3663, 282.5592, 257.9305,\n",
      "        244.1173, 244.4596, 264.1940])\n",
      "\n",
      "max's: tensor([0.8103, 0.9997, 0.9532,  ..., 0.9999, 0.4853, 0.9990])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 249, 296, 299, 302, 289, 267, 232, 244, 255]\n",
      "NdTc[:10]: tensor([124.6832, 300.0115, 288.4625, 299.3397, 300.0013, 282.6216, 257.8341,\n",
      "        244.2047, 244.5936, 264.1990])\n",
      "\n",
      "max's: tensor([0.8126, 0.9997, 0.9546,  ..., 0.9999, 0.4863, 0.9993])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 249, 296, 299, 306, 289, 267, 232, 244, 247]\n",
      "NdTc[:10]: tensor([124.6817, 300.0096, 288.2831, 299.3823, 299.7105, 282.5644, 257.9152,\n",
      "        243.9582, 244.6246, 264.1609])\n",
      "\n",
      "max's: tensor([0.8147, 0.9998, 0.9586,  ..., 0.9999, 0.4867, 0.9995])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 249, 295, 294, 302, 289, 267, 232, 244, 247]\n",
      "NdTc[:10]: tensor([124.6815, 300.0095, 288.4760, 299.5018, 299.8982, 282.1433, 257.3235,\n",
      "        243.1572, 244.4199, 263.9251])\n",
      "\n",
      "max's: tensor([0.8126, 0.9998, 0.9623,  ..., 0.9999, 0.4872, 0.9996])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 249, 295, 288, 302, 285, 267, 236, 240, 247]\n",
      "NdTc[:10]: tensor([124.6798, 300.0109, 288.1584, 299.1927, 299.7293, 281.9870, 257.1027,\n",
      "        242.8780, 244.2031, 263.7922])\n",
      "\n",
      "max's: tensor([0.8118, 0.9998, 0.9661,  ..., 0.9999, 0.4874, 0.9997])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 249, 295, 288, 302, 285, 267, 241, 240, 247]\n",
      "NdTc[:10]: tensor([124.6814, 300.0095, 288.1227, 299.9893, 299.9805, 281.8062, 256.8869,\n",
      "        241.9023, 244.0562, 263.6129])\n",
      "\n",
      "max's: tensor([0.8056, 0.9998, 0.9696,  ..., 0.9999, 0.4881, 0.9998])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 249, 295, 290, 302, 285, 267, 241, 240, 253]\n",
      "NdTc[:10]: tensor([124.6585, 300.0238, 288.1350, 299.7751, 299.6522, 281.7200, 256.8342,\n",
      "        241.2780, 243.9746, 263.6204])\n",
      "\n",
      "max's: tensor([0.7975, 0.9998, 0.9726,  ..., 0.9999, 0.4881, 0.9999])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 249, 295, 295, 302, 285, 271, 234, 249, 253]\n",
      "NdTc[:10]: tensor([124.6816, 300.0097, 288.0910, 299.8717, 299.8087, 281.3870, 256.3177,\n",
      "        240.5913, 243.8617, 263.5567])\n",
      "\n",
      "max's: tensor([0.7867, 0.9998, 0.9756,  ..., 0.9999, 0.4886, 0.9999])\n",
      "NdList[:10] inside getTotalPenalty(): [76, 249, 295, 303, 299, 285, 268, 228, 249, 253]\n",
      "NdTc[:10]: tensor([124.6762, 300.0006, 288.1780, 299.6451, 299.5713, 281.2278, 256.2304,\n",
      "        239.9556, 243.8443, 263.7951])\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "for epoch in range(150000):\n",
    "    optimizer.zero_grad()\n",
    "    x, y, z, NdTc = model()\n",
    "#     print(x.shape, y.shape)\n",
    "    loss = x + y + z\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        # (5000, 100): for each family (keep dim 0), find the most-weighted day\n",
    "        assignments = model.assignWeightsTc.argmax(dim=1).numpy()+1\n",
    "#         print(model.assignWeightsTc[0,:])\n",
    "#         print(model.assignWeightsTc[0,:].max(), model.assignWeightsTc[0,:].argmax())\n",
    "        \n",
    "#         print(assignments.max(), assignments.min())\n",
    "\n",
    "\n",
    "        print(\"max's:\", F.softmax(model.assignWeightsTc, dim=1).max(dim=1).values.data)\n",
    "\n",
    "        curScore = utils.getTotalScore(assignments, verbose=True)\n",
    "    \n",
    "        print(\"NdTc[:10]:\", NdTc[:10].data)\n",
    "        input(\"\")\n",
    "    \n",
    "#         print(x, y, z)\n",
    "#         print(curScore, z, loss)\n",
    "#         break\n",
    "#         pos = model.assignWeightsTc.argmax(1).numpy()\n",
    "#         a, b, v = cost_function(pos+1)\n",
    "#         score = a + b\n",
    "#         if score < best_score:\n",
    "#             best_score = score\n",
    "#             best_pos = pos\n",
    "#         x = np.round(x.item(), 3)\n",
    "#         y = np.round(y.item(), 3)\n",
    "#         print(f\"{epoch}\\t{x}\\t{y}\\t{score}\\t{a}\\t{b}\\t{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
