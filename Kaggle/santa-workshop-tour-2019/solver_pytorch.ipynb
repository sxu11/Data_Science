{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: constraints; cost function? why nega score?; goal is to achieve comparable performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/96/c97c8a0ea8f66de41f452925b521bcfdebef6fffb899dc704fc269d87563/torch-1.3.1-cp36-none-macosx_10_7_x86_64.whl (71.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 71.1MB 657kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/songxu/Code/venv/lib/python3.6/site-packages (from torch) (1.16.4)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.3.1\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/pavelvod/pytorch-starter-solution\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giftCostsNp (5000, 100): [i,j] means the gift cost when i-th family choses j-th day.\n",
    "row, col = 5000, 100\n",
    "giftCostsNp = np.zeros((row, col))\n",
    "familySizesNp = np.zeros((row, 1))\n",
    "\n",
    "familyDataNp = utils.readDataDf().values\n",
    "\n",
    "for i in range(row):\n",
    "    familySizesNp[i] = familyDataNp[i, -1]\n",
    "    for j in range(col):\n",
    "        giftCostsNp[i,j] = utils.getCurGift(assignDay=j, \n",
    "                                          familyPreferencesList=familyDataNp[i, 1:-1].tolist(), \n",
    "                                          familySize=familySizesNp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, giftCostsNp, familySizesNp):\n",
    "        super().__init__()\n",
    "        self.giftCostsTc = torch.from_numpy(giftCostsNp).type(torch.float32)\n",
    "        self.familySizesTc = torch.from_numpy(familySizesNp).type(torch.float32)\n",
    "        self.assignWeightsTc = torch.nn.Parameter(data=torch.Tensor(5000, 100), requires_grad=True)\n",
    "        self.assignWeightsTc.data.uniform_(0,5) # weight initialization?\n",
    "        \n",
    "    def forward(self):\n",
    "        assignProbTc = F.softmax(self.assignWeightsTc, dim=1)\n",
    "#         print(self.giftCostsTc.shape, assignProbTc.shape)\n",
    "        giftCostTotalTc = (self.giftCostsTc * assignProbTc).sum()\n",
    "        \n",
    "        NdTc = (assignProbTc.transpose(0,1) @ self.familySizesTc).sum(axis=1)\n",
    "#         print(F.softmax(NdTc).max(), F.softmax(NdTc).argmax())\n",
    "        NdTcCat = torch.zeros(101, dtype=torch.float32)\n",
    "        NdTcCat[:-1] = NdTc\n",
    "        NdTcCat[-1] = NdTc[-1]\n",
    "        \n",
    "#         print(\"exponent: \", 0.5+abs(NdTcCat[:-1]-NdTcCat[1:])/50.)\n",
    "        cleanCostTotalTc = ((NdTc-125.)/400. * NdTc**(0.5+abs(NdTcCat[:-1]-NdTcCat[1:])/50.)).sum()\n",
    "        \n",
    "        penaltyCostTotalTc = (torch.relu(125.-NdTc)**2 + torch.relu(NdTc-300.)**2).sum() * 1000000\n",
    "        return giftCostTotalTc, cleanCostTotalTc, penaltyCostTotalTc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/songxu/PycharmProjects/Data_Science/Kaggle/santa-workshop-tour-2019/utils.py'>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def cost_function():\n",
    "#     return None\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(giftCostsNp, familySizesNp)\n",
    "best_score = 10e10\n",
    "best_pos = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10620037 3574531.8473585383\n",
      "14194568.847358538 tensor(0., grad_fn=<MulBackward0>) tensor(10649078., grad_fn=<AddBackward0>)\n",
      "10612308 1.1879714001884732e+20\n",
      "1.1879714001885793e+20 tensor(0., grad_fn=<MulBackward0>) tensor(10458506., grad_fn=<AddBackward0>)\n",
      "10633174 4.7105822958330924e+27\n",
      "4.7105822958330924e+27 tensor(0., grad_fn=<MulBackward0>) tensor(10221365., grad_fn=<AddBackward0>)\n",
      "10575880 6.816053820153423e+22\n",
      "6.816053820153424e+22 tensor(0., grad_fn=<MulBackward0>) tensor(9929650., grad_fn=<AddBackward0>)\n",
      "10546788 8.224740658125752e+19\n",
      "8.224740658126807e+19 tensor(0., grad_fn=<MulBackward0>) tensor(9574804., grad_fn=<AddBackward0>)\n",
      "10527965 6.833060205689674e+16\n",
      "6.83306020674247e+16 tensor(0., grad_fn=<MulBackward0>) tensor(9215375., grad_fn=<AddBackward0>)\n",
      "10542625 48684799230405.05\n",
      "48684809773030.05 tensor(0., grad_fn=<MulBackward0>) tensor(8809120., grad_fn=<AddBackward0>)\n",
      "10536396 15931736145324.297\n",
      "15931746681720.297 tensor(0., grad_fn=<MulBackward0>) tensor(8372946.5000, grad_fn=<AddBackward0>)\n",
      "10551084 1550044536016.054\n",
      "1550055087100.054 tensor(0., grad_fn=<MulBackward0>) tensor(7901187.5000, grad_fn=<AddBackward0>)\n",
      "10559218 779627344934.6095\n",
      "779637904152.6095 tensor(0., grad_fn=<MulBackward0>) tensor(7411738.5000, grad_fn=<AddBackward0>)\n",
      "10558623 326358806665.66516\n",
      "326369365288.66516 tensor(0., grad_fn=<MulBackward0>) tensor(6916310.5000, grad_fn=<AddBackward0>)\n",
      "10553476 47388114248.50403\n",
      "47398667724.50403 tensor(0., grad_fn=<MulBackward0>) tensor(6445621., grad_fn=<AddBackward0>)\n",
      "10584380 95099754443.62743\n",
      "95110338823.62743 tensor(0., grad_fn=<MulBackward0>) tensor(6043014., grad_fn=<AddBackward0>)\n",
      "10596277 305236318325.7652\n",
      "305246914602.7652 tensor(0., grad_fn=<MulBackward0>) tensor(5679472., grad_fn=<AddBackward0>)\n",
      "10598101 19198574264.340782\n",
      "19209172365.340782 tensor(0., grad_fn=<MulBackward0>) tensor(5363220., grad_fn=<AddBackward0>)\n",
      "10606882 4301105315.035359\n",
      "4311712197.035359 tensor(0., grad_fn=<MulBackward0>) tensor(5087927.5000, grad_fn=<AddBackward0>)\n",
      "10610992 -230261786.77432755\n",
      "-219650794.77432755 tensor(323.3697, grad_fn=<MulBackward0>) tensor(4835219.5000, grad_fn=<AddBackward0>)\n",
      "10629956 -32444994248.241394\n",
      "-32434364292.241394 tensor(0., grad_fn=<MulBackward0>) tensor(4598706., grad_fn=<AddBackward0>)\n",
      "10635051 -38460832752.450485\n",
      "-38450197701.450485 tensor(176.2295, grad_fn=<MulBackward0>) tensor(4384457.5000, grad_fn=<AddBackward0>)\n",
      "10648122 -42088042690.77707\n",
      "-42077394568.77707 tensor(501.6033, grad_fn=<MulBackward0>) tensor(4188439.5000, grad_fn=<AddBackward0>)\n",
      "10668898 -20056021714.951267\n",
      "-20045352816.951267 tensor(184.6324, grad_fn=<MulBackward0>) tensor(4007174.5000, grad_fn=<AddBackward0>)\n",
      "10678871 -20250748943.859634\n",
      "-20240070072.859634 tensor(0., grad_fn=<MulBackward0>) tensor(3836480.2500, grad_fn=<AddBackward0>)\n",
      "10681676 -10440732106.684193\n",
      "-10430050430.684193 tensor(0., grad_fn=<MulBackward0>) tensor(3682526., grad_fn=<AddBackward0>)\n",
      "10683412 -8186693083.776557\n",
      "-8176009671.776557 tensor(0., grad_fn=<MulBackward0>) tensor(3535551.2500, grad_fn=<AddBackward0>)\n",
      "10673375 -6519494572.037121\n",
      "-6508821197.037121 tensor(12.9677, grad_fn=<MulBackward0>) tensor(3399568.7500, grad_fn=<AddBackward0>)\n",
      "10670693 -4129197541.1382756\n",
      "-4118526848.1382756 tensor(110.0489, grad_fn=<MulBackward0>) tensor(3272261.7500, grad_fn=<AddBackward0>)\n",
      "10689903 -4166149173.1473217\n",
      "-4155459270.1473217 tensor(1090.3567, grad_fn=<MulBackward0>) tensor(3154730.5000, grad_fn=<AddBackward0>)\n",
      "10698049 -2203154994.8953614\n",
      "-2192456945.8953614 tensor(127.0557, grad_fn=<MulBackward0>) tensor(3051884.5000, grad_fn=<AddBackward0>)\n",
      "10692081 -991464430.5042934\n",
      "-980772349.5042934 tensor(1112.0981, grad_fn=<MulBackward0>) tensor(2951808.2500, grad_fn=<AddBackward0>)\n",
      "10688013 -451717269.17742074\n",
      "-441029256.17742074 tensor(190.6941, grad_fn=<MulBackward0>) tensor(2861254.5000, grad_fn=<AddBackward0>)\n",
      "10682250 -259696799.83547768\n",
      "-249014549.83547768 tensor(382.5508, grad_fn=<MulBackward0>) tensor(2775676.5000, grad_fn=<AddBackward0>)\n",
      "10673568 -3153534771.217883\n",
      "-3142861203.217883 tensor(28754.8359, grad_fn=<MulBackward0>) tensor(2671134., grad_fn=<AddBackward0>)\n",
      "10672472 -3129971555.8154373\n",
      "-3119299083.8154373 tensor(17022.4922, grad_fn=<MulBackward0>) tensor(2613708.5000, grad_fn=<AddBackward0>)\n",
      "10675479 -3912944057.803214\n",
      "-3902268578.803214 tensor(29630.2520, grad_fn=<MulBackward0>) tensor(2538035.7500, grad_fn=<AddBackward0>)\n",
      "10672204 -20385050670.648823\n",
      "-20374378466.648823 tensor(95810.5234, grad_fn=<MulBackward0>) tensor(2411879.2500, grad_fn=<AddBackward0>)\n",
      "10676696 -19030439806.32998\n",
      "-19019763110.32998 tensor(105176.2578, grad_fn=<MulBackward0>) tensor(2352798.7500, grad_fn=<AddBackward0>)\n",
      "10680918 -19002542083.040028\n",
      "-18991861165.040028 tensor(104100.7344, grad_fn=<MulBackward0>) tensor(2297109.7500, grad_fn=<AddBackward0>)\n",
      "10687633 -19021412788.50693\n",
      "-19010725155.50693 tensor(100739.6406, grad_fn=<MulBackward0>) tensor(2242056.5000, grad_fn=<AddBackward0>)\n",
      "10692732 -19007488877.84128\n",
      "-18996796145.84128 tensor(100210.3828, grad_fn=<MulBackward0>) tensor(2189392.7500, grad_fn=<AddBackward0>)\n",
      "10690197 -19015465882.300007\n",
      "-19004775685.300007 tensor(99671.4375, grad_fn=<MulBackward0>) tensor(2139074., grad_fn=<AddBackward0>)\n",
      "10680803 -18992192343.301964\n",
      "-18981511540.301964 tensor(101912.9922, grad_fn=<MulBackward0>) tensor(2089845., grad_fn=<AddBackward0>)\n",
      "10684353 -18914535290.75966\n",
      "-18903850937.75966 tensor(100391.3594, grad_fn=<MulBackward0>) tensor(2042737.3750, grad_fn=<AddBackward0>)\n",
      "10679371 -14783978049.560514\n",
      "-14773298678.560514 tensor(100372.4297, grad_fn=<MulBackward0>) tensor(1995964.5000, grad_fn=<AddBackward0>)\n",
      "10674786 -14783811037.167295\n",
      "-14773136251.167295 tensor(100687.8438, grad_fn=<MulBackward0>) tensor(1950270.7500, grad_fn=<AddBackward0>)\n",
      "10659353 -14773075656.54761\n",
      "-14762416303.54761 tensor(97601.6250, grad_fn=<MulBackward0>) tensor(1907446.2500, grad_fn=<AddBackward0>)\n",
      "10652389 -14793864983.490816\n",
      "-14783212594.490816 tensor(104581.1797, grad_fn=<MulBackward0>) tensor(1865435.6250, grad_fn=<AddBackward0>)\n",
      "10662417 -14797386014.5551\n",
      "-14786723597.5551 tensor(106035.9844, grad_fn=<MulBackward0>) tensor(1823856.2500, grad_fn=<AddBackward0>)\n",
      "10682924 -10743036487.973858\n",
      "-10732353563.973858 tensor(102675.8984, grad_fn=<MulBackward0>) tensor(1783186.5000, grad_fn=<AddBackward0>)\n",
      "10690875 -10748015461.653748\n",
      "-10737324586.653748 tensor(87127.4844, grad_fn=<MulBackward0>) tensor(1748954.7500, grad_fn=<AddBackward0>)\n",
      "10707283 -10747633716.099731\n",
      "-10736926433.099731 tensor(108555.8828, grad_fn=<MulBackward0>) tensor(1712914.2500, grad_fn=<AddBackward0>)\n",
      "10704597 -12880387651.952036\n",
      "-12869683054.952036 tensor(100028.8125, grad_fn=<MulBackward0>) tensor(1673251.7500, grad_fn=<AddBackward0>)\n",
      "10704971 -12877624026.300577\n",
      "-12866919055.300577 tensor(100339.2969, grad_fn=<MulBackward0>) tensor(1638082.7500, grad_fn=<AddBackward0>)\n",
      "10707099 -12879741881.665838\n",
      "-12869034782.665838 tensor(99241.0781, grad_fn=<MulBackward0>) tensor(1604773.8750, grad_fn=<AddBackward0>)\n",
      "10714826 -12880139814.80663\n",
      "-12869424988.80663 tensor(100623.1250, grad_fn=<MulBackward0>) tensor(1572070.2500, grad_fn=<AddBackward0>)\n",
      "10718171 -12881491530.972622\n",
      "-12870773359.972622 tensor(102468.5469, grad_fn=<MulBackward0>) tensor(1541122.8750, grad_fn=<AddBackward0>)\n",
      "10718210 -12880929457.598637\n",
      "-12870211247.598637 tensor(101449.7422, grad_fn=<MulBackward0>) tensor(1508599.7500, grad_fn=<AddBackward0>)\n",
      "10714663 -10751150504.455505\n",
      "-10740435841.455505 tensor(89134.1719, grad_fn=<MulBackward0>) tensor(1487601.3750, grad_fn=<AddBackward0>)\n",
      "10708938 -12882868480.692646\n",
      "-12872159542.692646 tensor(96169.4531, grad_fn=<MulBackward0>) tensor(1450522., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-d12f6be7b988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(x.shape, y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-216-d0be3ace969a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0massignProbTc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massignWeightsTc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#         print(self.giftCostsTc.shape, assignProbTc.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mgiftCostTotalTc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgiftCostsTc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0massignProbTc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mNdTc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0massignProbTc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamilySizesTc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "for epoch in range(150000):\n",
    "    optimizer.zero_grad()\n",
    "    x, y, z = model()\n",
    "#     print(x.shape, y.shape)\n",
    "    loss = x + y + z\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        # (5000, 100): for each family (keep dim 0), find the most-weighted day\n",
    "        assignments = model.assignWeightsTc.argmax(dim=1).numpy()+1\n",
    "#         print(model.assignWeightsTc[0,:])\n",
    "#         print(model.assignWeightsTc[0,:].max(), model.assignWeightsTc[0,:].argmax())\n",
    "        \n",
    "#         print(assignments.max(), assignments.min())\n",
    "        curScore = utils.getTotalScore(assignments)\n",
    "#         print(x, y, z)\n",
    "        print(curScore, z, loss)\n",
    "#         break\n",
    "#         pos = model.assignWeightsTc.argmax(1).numpy()\n",
    "#         a, b, v = cost_function(pos+1)\n",
    "#         score = a + b\n",
    "#         if score < best_score:\n",
    "#             best_score = score\n",
    "#             best_pos = pos\n",
    "#         x = np.round(x.item(), 3)\n",
    "#         y = np.round(y.item(), 3)\n",
    "#         print(f\"{epoch}\\t{x}\\t{y}\\t{score}\\t{a}\\t{b}\\t{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
